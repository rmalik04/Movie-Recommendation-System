{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  70000\n",
      "Valid:  9992\n",
      "Test:  10000\n",
      "Number of users:  943\n",
      "Number of items:  1682\n"
     ]
    }
   ],
   "source": [
    "from train_valid_test_loader import load_train_valid_test_datasets\n",
    "\n",
    "# load data and partition them into train, validation, and test data  \n",
    "train_data, valid_data, test_data, n_users, n_items = load_train_valid_test_datasets()\n",
    "\n",
    "# print size of all data\n",
    "print(\"Train: \", train_data[0].size)\n",
    "print(\"Valid: \", valid_data[0].size)\n",
    "print(\"Test: \", test_data[0].size)\n",
    "print(\"Number of users: \", n_users)\n",
    "print(\"Number of items: \", n_items)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch       0.000 | loss_total     0.31928 | train_AUC     0.49769 | train_MAE     2.63940 | valid_AUC     0.50409 | valid_MAE     2.66135 | grad_wrt_mu 0.0000000000 | grad_wrt_b_per_user 0.0000000000 | grad_wrt_c_per_item 0.0000000000 | grad_wrt_U 0.0000000000 | grad_wrt_V 0.0000000000\n",
      "epoch       0.000 | loss_total     0.31602 | train_AUC     0.49769 | train_MAE     2.63940 | valid_AUC     0.50409 | valid_MAE     2.66135 | grad_wrt_mu 0.0000000000 | grad_wrt_b_per_user 0.0000000000 | grad_wrt_c_per_item 0.0000000000 | grad_wrt_U 0.0000000000 | grad_wrt_V 0.0000000000\n",
      "epoch       0.001 | loss_total     0.34201 | train_AUC     0.49769 | train_MAE     2.63940 | valid_AUC     0.50409 | valid_MAE     2.66135 | grad_wrt_mu 0.0000000000 | grad_wrt_b_per_user 0.0000000000 | grad_wrt_c_per_item 0.0000000000 | grad_wrt_U 0.0000000000 | grad_wrt_V 0.0000000000\n",
      "epoch       0.001 | loss_total     0.21135 | train_AUC     0.49769 | train_MAE     2.63940 | valid_AUC     0.50409 | valid_MAE     2.66135 | grad_wrt_mu 0.0000000000 | grad_wrt_b_per_user 0.0000000000 | grad_wrt_c_per_item 0.0000000000 | grad_wrt_U 0.0000000000 | grad_wrt_V 0.0000000000\n",
      "epoch       0.125 | loss_total     0.30840 | train_AUC     0.49769 | train_MAE     2.63940 | valid_AUC     0.50409 | valid_MAE     2.66135 | grad_wrt_mu 0.0000000000 | grad_wrt_b_per_user 0.0000000000 | grad_wrt_c_per_item 0.0000000000 | grad_wrt_U 0.0000000000 | grad_wrt_V 0.0000000000\n",
      "epoch       0.250 | loss_total     0.26349 | train_AUC     0.49769 | train_MAE     2.63940 | valid_AUC     0.50409 | valid_MAE     2.66135 | grad_wrt_mu 0.0000000000 | grad_wrt_b_per_user 0.0000000000 | grad_wrt_c_per_item 0.0000000000 | grad_wrt_U 0.0000000000 | grad_wrt_V 0.0000000000\n",
      "epoch       0.375 | loss_total     0.28985 | train_AUC     0.49769 | train_MAE     2.63940 | valid_AUC     0.50409 | valid_MAE     2.66135 | grad_wrt_mu 0.0000000000 | grad_wrt_b_per_user 0.0000000000 | grad_wrt_c_per_item 0.0000000000 | grad_wrt_U 0.0000000000 | grad_wrt_V 0.0000000000\n",
      "epoch       0.500 | loss_total     0.28162 | train_AUC     0.49769 | train_MAE     2.63940 | valid_AUC     0.50409 | valid_MAE     2.66135 | grad_wrt_mu 0.0000000000 | grad_wrt_b_per_user 0.0000000000 | grad_wrt_c_per_item 0.0000000000 | grad_wrt_U 0.0000000000 | grad_wrt_V 0.0000000000\n",
      "epoch       0.625 | loss_total     0.37917 | train_AUC     0.49769 | train_MAE     2.63940 | valid_AUC     0.50409 | valid_MAE     2.66135 | grad_wrt_mu 0.0000000000 | grad_wrt_b_per_user 0.0000000000 | grad_wrt_c_per_item 0.0000000000 | grad_wrt_U 0.0000000000 | grad_wrt_V 0.0000000000\n",
      "epoch       0.750 | loss_total     0.21654 | train_AUC     0.49769 | train_MAE     2.63940 | valid_AUC     0.50409 | valid_MAE     2.66135 | grad_wrt_mu 0.0000000000 | grad_wrt_b_per_user 0.0000000000 | grad_wrt_c_per_item 0.0000000000 | grad_wrt_U 0.0000000000 | grad_wrt_V 0.0000000000\n",
      "epoch       0.875 | loss_total     0.37136 | train_AUC     0.49769 | train_MAE     2.63940 | valid_AUC     0.50409 | valid_MAE     2.66135 | grad_wrt_mu 0.0000000000 | grad_wrt_b_per_user 0.0000000000 | grad_wrt_c_per_item 0.0000000000 | grad_wrt_U 0.0000000000 | grad_wrt_V 0.0000000000\n",
      "epoch       1.000 | loss_total     0.22887 | train_AUC     0.49769 | train_MAE     2.63940 | valid_AUC     0.50409 | valid_MAE     2.66135 | grad_wrt_mu 0.0000000000 | grad_wrt_b_per_user 0.0000000000 | grad_wrt_c_per_item 0.0000000000 | grad_wrt_U 0.0000000000 | grad_wrt_V 0.0000000000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m two_factors_SGD_model\u001b[38;5;241m.\u001b[39minit_parameter_dict(n_users, n_items, train_data)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# fit model to training data\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[43mtwo_factors_SGD_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\Machine Learning\\Project 2\\projB-release\\src_starter\\AbstractBaseCollabFilterSGD.py:181\u001b[0m, in \u001b[0;36mAbstractBaseCollabFilterSGD.fit\u001b[1;34m(self, train_data_tuple, valid_data_tuple)\u001b[0m\n\u001b[0;32m    172\u001b[0m batch_loader\u001b[38;5;241m.\u001b[39mshuffle()\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, batch_tuple \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(batch_loader):\n\u001b[0;32m    175\u001b[0m \n\u001b[0;32m    176\u001b[0m     \u001b[38;5;66;03m## Compute loss and gradient\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;66;03m#   Keys are string names of individual parameters\u001b[39;00m\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;66;03m#   Values are autograd-generated numpy arrays\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m     loss, grad_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalc_loss_and_grad_wrt_parameter_dict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_tuple\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;66;03m## Rescale loss and gradient vectors\u001b[39;00m\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;66;03m# So we always estimate the *per-example loss*\u001b[39;00m\n\u001b[0;32m    186\u001b[0m     n_per_batch \u001b[38;5;241m=\u001b[39m batch_tuple[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msize\n",
      "File \u001b[1;32m~\\Documents\\Machine Learning\\Project 2\\projB-release\\src_starter\\AbstractBaseCollabFilterSGD.py:105\u001b[0m, in \u001b[0;36mAbstractBaseCollabFilterSGD.calc_loss_and_grad_wrt_parameter_dict\u001b[1;34m(self, param_dict, data_tuple)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_calc_loss_and_grad_wrt_param_dict \u001b[38;5;241m=\u001b[39m value_and_grad(\n\u001b[0;32m    104\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcalc_loss_wrt_parameter_dict, argnum\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m--> 105\u001b[0m loss, grad_dict_tuple \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_calc_loss_and_grad_wrt_param_dict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    106\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_tuple\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    107\u001b[0m grad_dict \u001b[38;5;241m=\u001b[39m grad_dict_tuple[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;66;03m# Unpack tuple output of autograd\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss, grad_dict\n",
      "File \u001b[1;32m~\\miniconda\\envs\\cs135_env\\lib\\site-packages\\autograd\\wrap_util.py:20\u001b[0m, in \u001b[0;36munary_to_nary.<locals>.nary_operator.<locals>.nary_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     19\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(args[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m argnum)\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m unary_operator(unary_f, x, \u001b[38;5;241m*\u001b[39mnary_op_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnary_op_kwargs)\n",
      "File \u001b[1;32m~\\miniconda\\envs\\cs135_env\\lib\\site-packages\\autograd\\differential_operators.py:143\u001b[0m, in \u001b[0;36mvalue_and_grad\u001b[1;34m(fun, x)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m vspace(ans)\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue_and_grad only applies to real scalar-output \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    141\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunctions. Try jacobian, elementwise_grad or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    142\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mholomorphic_grad.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ans, \u001b[43mvjp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvspace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mans\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda\\envs\\cs135_env\\lib\\site-packages\\autograd\\core.py:14\u001b[0m, in \u001b[0;36mmake_vjp.<locals>.vjp\u001b[1;34m(g)\u001b[0m\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvjp\u001b[39m(g): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackward_pass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_node\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda\\envs\\cs135_env\\lib\\site-packages\\autograd\\core.py:21\u001b[0m, in \u001b[0;36mbackward_pass\u001b[1;34m(g, end_node)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m toposort(end_node):\n\u001b[0;32m     20\u001b[0m     outgrad \u001b[38;5;241m=\u001b[39m outgrads\u001b[38;5;241m.\u001b[39mpop(node)\n\u001b[1;32m---> 21\u001b[0m     ingrads \u001b[38;5;241m=\u001b[39m \u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvjp\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutgrad\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m parent, ingrad \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(node\u001b[38;5;241m.\u001b[39mparents, ingrads):\n\u001b[0;32m     23\u001b[0m         outgrads[parent] \u001b[38;5;241m=\u001b[39m add_outgrads(outgrads\u001b[38;5;241m.\u001b[39mget(parent), ingrad)\n",
      "File \u001b[1;32m~\\miniconda\\envs\\cs135_env\\lib\\site-packages\\autograd\\core.py:67\u001b[0m, in \u001b[0;36mdefvjp.<locals>.vjp_argnums.<locals>.<lambda>\u001b[1;34m(g)\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m     65\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVJP of \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m wrt argnum 0 not defined\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(fun\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m))\n\u001b[0;32m     66\u001b[0m     vjp \u001b[38;5;241m=\u001b[39m vjpfun(ans, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 67\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mlambda\u001b[39;00m g: (\u001b[43mvjp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m)\u001b[49m,)\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m L \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m     69\u001b[0m     argnum_0, argnum_1 \u001b[38;5;241m=\u001b[39m argnums\n",
      "File \u001b[1;32m~\\miniconda\\envs\\cs135_env\\lib\\site-packages\\autograd\\numpy\\numpy_vjps.py:660\u001b[0m, in \u001b[0;36munbroadcast_f.<locals>.<lambda>\u001b[1;34m(g)\u001b[0m\n\u001b[0;32m    658\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21munbroadcast_f\u001b[39m(target, f):\n\u001b[0;32m    659\u001b[0m     target_meta \u001b[38;5;241m=\u001b[39m anp\u001b[38;5;241m.\u001b[39mmetadata(target)\n\u001b[1;32m--> 660\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mlambda\u001b[39;00m g: unbroadcast(\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m)\u001b[49m, target_meta)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from CollabFilterOneVectorPerItem import CollabFilterOneVectorPerItem\n",
    "\n",
    "# Create model and initialize appropriate data\n",
    "two_factors_SGD_model = CollabFilterOneVectorPerItem(n_epochs=600, \n",
    "                                                   batch_size=32, \n",
    "                                                   step_size=0.2,\n",
    "                                                   n_factors=50, \n",
    "                                                   alpha=0.0)\n",
    "two_factors_SGD_model.init_parameter_dict(n_users, n_items, train_data)\n",
    "\n",
    "# fit model to training data\n",
    "two_factors_SGD_model.fit(train_data, valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
